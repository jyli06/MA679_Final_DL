{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9921dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "def make_windows(\n",
    "  arr,\n",
    "  win_size,\n",
    "  step_size,\n",
    "):\n",
    "  w_list = list()\n",
    "  n_records = arr.shape[0]\n",
    "  remainder = (n_records - win_size) % step_size \n",
    "  num_windows = 1 + int((n_records - win_size - remainder) / step_size)\n",
    "  for k in range(num_windows):\n",
    "    w_list.append(arr[k*step_size:win_size-1+k*step_size+1])\n",
    "  return np.array(w_list)\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header = None)\n",
    "    return dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae833f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat      = scipy.io.loadmat('binned_zscore.mat') \n",
    "Behavior = scipy.io.loadmat('binned_behavior.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e2ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 6184)\n",
      "(2, 6184)\n"
     ]
    }
   ],
   "source": [
    "zscore = pd.DataFrame(mat['binned_zscore']).T.values\n",
    "behavior = pd.DataFrame(Behavior['binned_behavior']).values\n",
    "\n",
    "drop_index = np.where((behavior[0, :] + behavior[1, :]) == 0)\n",
    "zscore = np.delete(zscore, drop_index, axis = 1)\n",
    "behavior = np.delete(behavior, drop_index, axis = 1)\n",
    "print(zscore.shape)\n",
    "print(behavior.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da360c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6180, 110, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_zscore = []\n",
    "for i in range(110):\n",
    "    tr_zscore.append(make_windows(zscore[i, :], 5, 1))\n",
    "tr_zscore = np.asarray(tr_zscore)\n",
    "window_zscore = []\n",
    "for i in range(6180):\n",
    "    window_zscore.append(tr_zscore[:, i, :])\n",
    "window_zscore = np.asarray(window_zscore)\n",
    "window_zscore.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d85e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = np.delete(behavior, range(4), axis = 1)\n",
    "window_behavior = np.zeros((6180))\n",
    "for i in range(6180):\n",
    "    if behavior[0, i] == 1:\n",
    "        window_behavior[i] = 1\n",
    "    else:\n",
    "        window_behavior[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0608d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "index0 = np.where(window_behavior == 0)\n",
    "index1 = np.where(window_behavior == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b786a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535\n",
      "4645\n"
     ]
    }
   ],
   "source": [
    "print(len(index0[0]))\n",
    "print(len(index1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e009cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_zscore   = np.delete(window_zscore  , 6179, axis = 0)\n",
    "window_behavior = np.delete(window_behavior, 0   , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "163c141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6179, 110, 5)\n",
      "(6179,)\n"
     ]
    }
   ],
   "source": [
    "print(window_zscore  .shape)\n",
    "print(window_behavior.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77cf58",
   "metadata": {},
   "source": [
    "# Model Build: 1D CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31adbc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4325, 110, 5)\n",
      "(4325,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(window_zscore, window_behavior, test_size = 0.3, random_state = 1)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "100d9152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3_input (InputLayer)  [(None, 110, 5)]         0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 108, 128)          2048      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 54, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 52, 64)            24640     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 26, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 24, 32)            6176      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 1)                 135617    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,481\n",
      "Trainable params: 168,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1d_encoder = Sequential([\n",
    "    Conv1D(filters = 128, kernel_size = 3, activation = 'relu', input_shape = (110, 5)), \n",
    "    MaxPooling1D(pool_size = 2),\n",
    "    Conv1D(filters = 64, kernel_size = 3, activation = 'relu'), \n",
    "    # Dropout(0.5), \n",
    "    MaxPooling1D(pool_size = 2), \n",
    "    Conv1D(filters = 32, kernel_size = 3, activation = 'relu'), \n",
    "    MaxPooling1D(pool_size = 2), \n",
    "    Flatten()\n",
    "])\n",
    "cnn1d_decoder = Sequential([\n",
    "    Dense(256, activation = 'relu', input_shape = (cnn1d_encoder.output.shape[1], )), \n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "cnn1d_autoencoder = Model(inputs = cnn1d_encoder.input, outputs = cnn1d_decoder(cnn1d_encoder.output))\n",
    "cnn1d_autoencoder.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "cnn1d_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d9e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 0.3768 - accuracy: 0.8370 - val_loss: 0.3303 - val_accuracy: 0.8601\n",
      "Epoch 2/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.1602 - accuracy: 0.9355 - val_loss: 0.2140 - val_accuracy: 0.9133\n",
      "Epoch 3/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.0923 - accuracy: 0.9633 - val_loss: 0.1837 - val_accuracy: 0.9399\n",
      "Epoch 4/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 0.1840 - val_accuracy: 0.9387\n",
      "Epoch 5/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.0584 - accuracy: 0.9801 - val_loss: 0.1186 - val_accuracy: 0.9526\n",
      "Epoch 6/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0469 - accuracy: 0.9838 - val_loss: 0.1117 - val_accuracy: 0.9688\n",
      "Epoch 7/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0407 - accuracy: 0.9844 - val_loss: 0.1468 - val_accuracy: 0.9514\n",
      "Epoch 8/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.1378 - val_accuracy: 0.9642\n",
      "Epoch 9/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.1113 - val_accuracy: 0.9688\n",
      "Epoch 10/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.0753 - val_accuracy: 0.9780\n",
      "Epoch 11/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.0834 - val_accuracy: 0.9803\n",
      "Epoch 12/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.1157 - val_accuracy: 0.9688\n",
      "Epoch 13/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0319 - accuracy: 0.9879 - val_loss: 0.1266 - val_accuracy: 0.9491\n",
      "Epoch 14/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 0.0976 - val_accuracy: 0.9734\n",
      "Epoch 15/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0843 - val_accuracy: 0.9780\n",
      "Epoch 16/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.1070 - val_accuracy: 0.9653\n",
      "Epoch 17/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.0871 - val_accuracy: 0.9792\n",
      "Epoch 18/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0110 - accuracy: 0.9951 - val_loss: 0.1229 - val_accuracy: 0.9780\n",
      "Epoch 19/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.1177 - val_accuracy: 0.9711\n",
      "Epoch 20/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.1139 - val_accuracy: 0.9792\n",
      "Epoch 21/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.1443 - val_accuracy: 0.9630\n",
      "Epoch 22/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.1104 - val_accuracy: 0.9711\n",
      "Epoch 23/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 0.1206 - val_accuracy: 0.9769\n",
      "Epoch 24/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1430 - val_accuracy: 0.9757\n",
      "Epoch 25/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1343 - val_accuracy: 0.9780\n",
      "Epoch 26/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.1110 - val_accuracy: 0.9688\n",
      "Epoch 27/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.1396 - val_accuracy: 0.9607\n",
      "Epoch 28/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.3941 - val_accuracy: 0.9410\n",
      "Epoch 29/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0315 - accuracy: 0.9887 - val_loss: 0.0904 - val_accuracy: 0.9803\n",
      "Epoch 30/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.1353 - val_accuracy: 0.9699\n",
      "Epoch 31/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.1092 - val_accuracy: 0.9665\n",
      "Epoch 32/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.1477 - val_accuracy: 0.9792\n",
      "Epoch 33/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1459 - val_accuracy: 0.9676\n",
      "Epoch 34/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.1320 - val_accuracy: 0.9803\n",
      "Epoch 35/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 9.3442e-04 - accuracy: 0.9994 - val_loss: 0.1428 - val_accuracy: 0.9815\n",
      "Epoch 36/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.4691e-04 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9815\n",
      "Epoch 37/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.1017e-04 - accuracy: 0.9994 - val_loss: 0.1726 - val_accuracy: 0.9769\n",
      "Epoch 38/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1273 - val_accuracy: 0.9815\n",
      "Epoch 39/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.6733e-04 - accuracy: 0.9997 - val_loss: 0.1269 - val_accuracy: 0.9792\n",
      "Epoch 40/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0307 - accuracy: 0.9931 - val_loss: 0.1274 - val_accuracy: 0.9676\n",
      "Epoch 41/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.1543 - val_accuracy: 0.9503\n",
      "Epoch 42/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.1388 - val_accuracy: 0.9734\n",
      "Epoch 43/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.1178 - val_accuracy: 0.9688\n",
      "Epoch 44/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1457 - val_accuracy: 0.9769\n",
      "Epoch 45/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1162 - val_accuracy: 0.9723\n",
      "Epoch 46/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.0860 - val_accuracy: 0.9769\n",
      "Epoch 47/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.1338 - val_accuracy: 0.9734\n",
      "Epoch 48/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 0.1456 - val_accuracy: 0.9711\n",
      "Epoch 49/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 0.1701 - val_accuracy: 0.9769\n",
      "Epoch 50/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.3644e-04 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9757\n",
      "Epoch 51/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.3016e-04 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9769\n",
      "Epoch 52/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.7033e-04 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9769\n",
      "Epoch 53/200\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 9.8883e-05 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9769\n",
      "Epoch 54/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.6698e-05 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9757\n",
      "Epoch 55/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.8593e-05 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9757\n",
      "Epoch 56/200\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 3.4781e-05 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9757\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 1s 11ms/step - loss: 2.5537e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9746\n",
      "Epoch 58/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.8061e-05 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9746\n",
      "Epoch 59/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.3558e-05 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9757\n",
      "Epoch 60/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.0117e-05 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9757\n",
      "Epoch 61/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 8.1900e-06 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9757\n",
      "Epoch 62/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 7.0319e-06 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9757\n",
      "Epoch 63/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 5.0977e-06 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9757\n",
      "Epoch 64/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.3799e-06 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9757\n",
      "Epoch 65/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 3.6817e-06 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9757\n",
      "Epoch 66/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.9418e-06 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9757\n",
      "Epoch 67/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.5029e-06 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9757\n",
      "Epoch 68/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.1010e-06 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9757\n",
      "Epoch 69/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.8781e-06 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9757\n",
      "Epoch 70/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.5106e-06 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9757\n",
      "Epoch 71/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.3386e-06 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9757\n",
      "Epoch 72/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.1681e-06 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9757\n",
      "Epoch 73/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 9.7164e-07 - accuracy: 1.0000 - val_loss: 0.2830 - val_accuracy: 0.9757\n",
      "Epoch 74/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 8.8099e-07 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9757\n",
      "Epoch 75/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 7.4826e-07 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9757\n",
      "Epoch 76/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 6.9416e-07 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9769\n",
      "Epoch 77/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 6.0852e-07 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9769\n",
      "Epoch 78/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 5.4157e-07 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9769\n",
      "Epoch 79/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.7845e-07 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9769\n",
      "Epoch 80/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.4004e-07 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9769\n",
      "Epoch 81/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 3.9442e-07 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9769\n",
      "Epoch 82/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.4619e-07 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9769\n",
      "Epoch 83/200\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 3.3595e-07 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9769\n",
      "Epoch 84/200\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 2.9157e-07 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9769\n",
      "Epoch 85/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.6567e-07 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9769\n",
      "Epoch 86/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.4048e-07 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9769\n",
      "Epoch 87/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.1599e-07 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9769\n",
      "Epoch 88/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.9146e-07 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9769\n",
      "Epoch 89/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.7485e-07 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9769\n",
      "Epoch 90/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.6054e-07 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9769\n",
      "Epoch 91/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.4619e-07 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9769\n",
      "Epoch 92/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.3178e-07 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9769\n",
      "Epoch 93/200\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 1.1761e-07 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9769\n",
      "Epoch 94/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.1253e-07 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9769\n",
      "Epoch 95/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 9.8827e-08 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9769\n",
      "Epoch 96/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 8.9910e-08 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9769\n",
      "Epoch 97/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 8.1066e-08 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9769\n",
      "Epoch 98/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 7.8207e-08 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9769\n",
      "Epoch 99/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.8424e-08 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9769\n",
      "Epoch 100/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.3073e-08 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9769\n",
      "Epoch 101/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 5.7714e-08 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9769\n",
      "Epoch 102/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 5.3029e-08 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9769\n",
      "Epoch 103/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.7094e-08 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9769\n",
      "Epoch 104/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.2449e-08 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9769\n",
      "Epoch 105/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.8948e-08 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9769\n",
      "Epoch 106/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.5560e-08 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9769\n",
      "Epoch 107/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.3632e-08 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9769\n",
      "Epoch 108/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.0403e-08 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9769\n",
      "Epoch 109/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.8580e-08 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9769\n",
      "Epoch 110/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.6251e-08 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9769\n",
      "Epoch 111/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.4386e-08 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 2.3241e-08 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9769\n",
      "Epoch 113/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.1604e-08 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9769\n",
      "Epoch 114/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.0462e-08 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9769\n",
      "Epoch 115/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.8876e-08 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9769\n",
      "Epoch 116/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.7858e-08 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9769\n",
      "Epoch 117/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.7472e-08 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9769\n",
      "Epoch 118/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.6210e-08 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9769\n",
      "Epoch 119/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.5277e-08 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9769\n",
      "Epoch 120/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.4304e-08 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9769\n",
      "Epoch 121/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.3254e-08 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9769\n",
      "Epoch 122/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.2625e-08 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9769\n",
      "Epoch 123/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.2029e-08 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9769\n",
      "Epoch 124/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.1209e-08 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9769\n",
      "Epoch 125/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.0680e-08 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9769\n",
      "Epoch 126/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.0080e-08 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9769\n",
      "Epoch 127/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 9.5650e-09 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9769\n",
      "Epoch 128/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 8.9870e-09 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9769\n",
      "Epoch 129/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 8.6220e-09 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9769\n",
      "Epoch 130/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 8.0206e-09 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9769\n",
      "Epoch 131/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 7.6987e-09 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9769\n",
      "Epoch 132/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 7.3743e-09 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9769\n",
      "Epoch 133/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.9028e-09 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9769\n",
      "Epoch 134/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.5300e-09 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9769\n",
      "Epoch 135/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.3182e-09 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9769\n",
      "Epoch 136/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 6.0175e-09 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9769\n",
      "Epoch 137/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 5.6936e-09 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9769\n",
      "Epoch 138/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 5.4454e-09 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9769\n",
      "Epoch 139/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 5.1979e-09 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9769\n",
      "Epoch 140/200\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 4.9861e-09 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9769\n",
      "Epoch 141/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.7474e-09 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9769\n",
      "Epoch 142/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.4535e-09 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9769\n",
      "Epoch 143/200\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 4.3259e-09 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9769\n",
      "Epoch 144/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 4.1063e-09 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9769\n",
      "Epoch 145/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.9240e-09 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9769\n",
      "Epoch 146/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.7646e-09 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9769\n",
      "Epoch 147/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.5865e-09 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9769\n",
      "Epoch 148/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.4158e-09 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.9769\n",
      "Epoch 149/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.2074e-09 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9769\n",
      "Epoch 150/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.1119e-09 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9769\n",
      "Epoch 151/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.9844e-09 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9769\n",
      "Epoch 152/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.8535e-09 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.9769\n",
      "Epoch 153/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.6896e-09 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9769\n",
      "Epoch 154/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.5644e-09 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9769\n",
      "Epoch 155/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.4857e-09 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9769\n",
      "Epoch 156/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.3834e-09 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.9769\n",
      "Epoch 157/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.2668e-09 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9769\n",
      "Epoch 158/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 2.1887e-09 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9769\n",
      "Epoch 159/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 2.0702e-09 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9769\n",
      "Epoch 160/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.9829e-09 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9769\n",
      "Epoch 161/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.8753e-09 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9769\n",
      "Epoch 162/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.7810e-09 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9769\n",
      "Epoch 163/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.7454e-09 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9769\n",
      "Epoch 164/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.6679e-09 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9769\n",
      "Epoch 165/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.5715e-09 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9769\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 1s 10ms/step - loss: 1.5461e-09 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9769\n",
      "Epoch 167/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 1.4408e-09 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9769\n",
      "Epoch 168/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 1.3958e-09 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9769\n",
      "Epoch 169/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 1.3050e-09 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9769\n",
      "Epoch 170/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 1.2603e-09 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9769\n",
      "Epoch 171/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 1.2125e-09 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9769\n",
      "Epoch 172/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 1.1571e-09 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9769\n",
      "Epoch 173/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.0993e-09 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9769\n",
      "Epoch 174/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.0386e-09 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9769\n",
      "Epoch 175/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.0160e-09 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9769\n",
      "Epoch 176/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 9.7158e-10 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9769\n",
      "Epoch 177/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 9.2489e-10 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9769\n",
      "Epoch 178/200\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 8.9156e-10 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9769\n",
      "Epoch 179/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 8.4531e-10 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9769\n",
      "Epoch 180/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 8.1757e-10 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9769\n",
      "Epoch 181/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 7.9065e-10 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9769\n",
      "Epoch 182/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 7.3471e-10 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9769\n",
      "Epoch 183/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 7.0660e-10 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9769\n",
      "Epoch 184/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 6.9007e-10 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9769\n",
      "Epoch 185/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 6.5712e-10 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9769\n",
      "Epoch 186/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 6.2458e-10 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.9769\n",
      "Epoch 187/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 6.0831e-10 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9769\n",
      "Epoch 188/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 5.8330e-10 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9769\n",
      "Epoch 189/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 5.5173e-10 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9769\n",
      "Epoch 190/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 5.3717e-10 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9769\n",
      "Epoch 191/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 5.0985e-10 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9769\n",
      "Epoch 192/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.9072e-10 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9769\n",
      "Epoch 193/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.6409e-10 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9769\n",
      "Epoch 194/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.4838e-10 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9769\n",
      "Epoch 195/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.3747e-10 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9769\n",
      "Epoch 196/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.2025e-10 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9769\n",
      "Epoch 197/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 4.0822e-10 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9769\n",
      "Epoch 198/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.9359e-10 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9769\n",
      "Epoch 199/200\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 3.8497e-10 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9769\n",
      "Epoch 200/200\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 3.7168e-10 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "model_history2 = cnn1d_autoencoder.fit(X_train, Y_train, epochs=200, batch_size=32,\n",
    "                                       validation_split = .2, \n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bde97b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.plot(model_history2.history['accuracy'], label='train')\n",
    "pyplot.plot(model_history2.history['val_accuracy'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd82796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = (cnn1d_autoencoder.predict(X_test)> 0.5).reshape((1854, ))\n",
    "pred = np.multiply(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af60bdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1854,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a519f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9795037756202805"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b31d7693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1854 - (0.9795037756202805 * 1854)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
